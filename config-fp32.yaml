# config-fp32.yaml
# ──────────────────────────────────────────────────────────────
# 설정 핵심:
# 1) quantization 섹션 제거
# 2) 사전학습 가중치가 있는 timm/torchvision 모델만 사용
# 3) 프로젝트·체크포인트 이름도 FP32 중심으로 변경
# ──────────────────────────────────────────────────────────────

hyperparameters:
  model_name: "mobilenet_v3_large_100"   # timm·torchvision 둘 다 인식
  seed: 2025
  batch_size: 32
  epochs: 10000
  patience: 35
  max_checkpoints: 3
  num_workers: 8

data:
  root: "./dataset/StitchingNet"
  train_ratio: 0.70   # 70% train
  val_ratio: 0.15     # 15% validation, 나머지 15% test
  use_augmentation: 0 # 증강 버전 (0 = 없음)

training:
  project_name: "StitchingNet-FP32-epoch10"
  use_dataparallel: false      # GPU가 여러 개면 true 로 변경 가능
  checkpoint_base_dir: "./checkpoint/fp32-epoch10/"
  freeze_layers: false         # 백본 고정 여부

  # 학습률 설정
  base_lr: 1e-4
  head_lr: 1e-3

  # CosineAnnealing 스케줄러
  use_scheduler: true
  T_max: 100    # 보통 epochs 와 동일하게 설정
  eta_min: 1e-7
