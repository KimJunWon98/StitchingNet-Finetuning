hyperparameters:
  # model_name: "timm_fuse_mobilenetv3_small_075" # 1. timm 모델에 fuse 적용하기

  # model_name: "timm_mobilenetv2_050"  # 2. timm 모델 가중치를 torchvision 모델에 맵핑, QAT Inference 시 성능이 안나오는 문제.
  model_name: "timm_mobilenetv3_small_075"
  
  # model_name: "mobilenet_v3_large" # 3. torchvision 사전학습 모델  , QAT Inference 시에 문제 없음.
  # model_name: "mobilenet_v2"

  # model_name: "mobilenet_v2_custom_025" # 4. torchvision 알파 값 커스텀 모델, 사전학습 X
  # model_name: "mobilenet_v2_custom_050"
  # model_name: "mobilenet_v3_custom_050"
  # model_name: "mobilenet_v3_custom_025"
  # model_name: "mobilenet_v3_custom_075"
  # model_name: "mobilenet_v3_small_custom_050"
  seed : 2025
  batch_size: 32
  epochs: 300
  patience: 15
  max_checkpoints : 3
  num_workers: 8
  layers:
    - [all]

quantization:
  # x86/서버용은 보통 "fbgemm", ARM(Android, 라즈베리파이 등)은 "qnnpack"
  qengine: "fbgemm"

data:
  root: "./dataset/StitchingNet"
  train_ratio: 0.7
  val_ratio: 0.15
  use_augmentation: 2

training:
  project_name: "StitchingNet-FinuTuning-QAT-custom"
  use_dataparallel: false # (true로 설정 시, GPU가 2개 이상인 경우 DataParallel 적용)
  checkpoint_base_dir: "./checkpoint/quantization/"   # 체크포인트를 저장할 기본 경로
  freeze_layers: false # 모든 파라미터(requires_grad=True)

  # 아래 두 파라미터가 base_lr, head_lr
  base_lr: 1e-4
  head_lr: 1e-3

  # 스케줄러 사용 여부 및 설정 (cosine annealing)
  use_scheduler: true
  T_max: 75      # 보통 epoch 수만큼 지정
  eta_min: 1e-7  # learning rate가 내려갈 최소값